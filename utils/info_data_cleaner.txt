Operational logic: data_cleaner defines a CleaningConfig dataclass and three tiers of cleaning—clean_string, clean_series, and clean_headers—then composes them via robust_clean (and wrapper quick_clean) to canonicalize text by normalizing Unicode, replacing homoglyphs/smart punctuation, stripping control characters, trimming, and sanitizing headers before overwriting object/string columns.
Real-world problem addressed: it pre-processes messy DataFrames containing BOMs, smart quotes, homoglyphs, and inconsistent whitespace so downstream SQL loads and merges avoid unexpected characters or header names.
Control flow: inputs hit clean_string (short-circuiting non-strings and NaNs), clean_series vectorizes replacements while honoring handle_na, clean_headers sanitizes column labels and resolves duplicates, and robust_clean applies header cleaning before iterating target columns selected automatically or explicitly, with quick_clean reusing defaults focused on BOM/trim/smart-character handling.
Failure modes: non-object/string columns are explicitly skipped by clean_series returning the input unchanged; handle_na maps tokens like 'nan' and 'null' to NaN; custom_map, control-character stripping, and remove_special_chars can drop characters without notice; header sanitization renames and de-duplicates columns without notifying callers (filling empties as col_n); large DataFrames still pay per-column string operations.
